{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/CFG_grammars/blob/main/parsing_and_generating_with_a_CFG_SM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parsing and generating sentences with context-free grammars\n",
        "\n",
        "In this part of the Week 3 lab, we're looking at simple phrase-structure grammars and how they can be used to analyse and generate sentences. We will look at ambiguity and how differences in parses (analyses) can account for and explain syntactic ambiguity.\n",
        "\n",
        "To help us do this we're using a tool called NLTK (Natural Language Tool Kit) which is pre-installed on Colab. Have a quick look at the intro here: https://www.nltk.org/index.html\n",
        "\n",
        "Let's jump right in with a simple grammar. Recall S=sentence, NP=noun phrase, VP=verb phrase, PP=prepositional phrase, Det=determiner, N=noun, V=verb, P=preposition. Words surrounded by single quotes are lexical items which are in CFG terms the terminal nodes of the grammar (i.e. they cannot be parent nodes to other nodes).\n",
        "\n",
        "In the code below, we start by importing the context-free grammar (CFG) class from NLTK to use with a simple predefined grammar:"
      ],
      "metadata": {
        "id": "ta3NwLrh1SmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKTg6LMrDKy8"
      },
      "outputs": [],
      "source": [
        "from nltk import CFG\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    PP -> P NP\n",
        "    NP -> Det N | NP PP\n",
        "    VP -> V NP | VP PP\n",
        "    Det -> 'a' | 'the'\n",
        "    N -> 'dog' | 'cat'\n",
        "    V -> 'chased' | 'sat'\n",
        "    P -> 'on' | 'in'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall from the lectures that these are production rules which you can read, e.g. for the first one, as *a sentence can consist of a noun phrase followed by a verb phrase*.\n",
        "\n",
        "Note how some of the rules have a pipe symbol on the right hand side which can be interpreted as 'or.' Rules with *n* pipe symbols are in fact *n*+1 production rules. For example, the rule\n",
        "\n",
        "    N -> 'dog' | 'cat'\n",
        "\n",
        "is in fact the following two rules:\n",
        "\n",
        "    N -> 'dog'\n",
        "    N -> 'cat'\n",
        "\n",
        "Once we have specified a grammar we can ask questions about it, for example what its start symbol is (which must be the root in all parse trees), and what production rules it contains, as below. For more information on what else you can do with a CFG see here: https://www.nltk.org/api/nltk.grammar.CFG.html"
      ],
      "metadata": {
        "id": "LkalW6-96eIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar.start()"
      ],
      "metadata": {
        "id": "wqA5UiUkGouu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grammar.productions()"
      ],
      "metadata": {
        "id": "PsbMGvC1Gy5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parsing sentences with a CFG\n",
        "\n",
        "Next, we're going to use the grammar from above to parse some sentences. We start by importing the ChartParser class from NLTK. A chart parser is able to apply a CFG to a sentence in order to parse it, see here for more info: https://en.wikipedia.org/wiki/Chart_parser\n",
        "\n",
        "Then we create a parser for the grammar from above.\n",
        "\n",
        "Let's give it a sentence to parse: *a cat chased a dog*"
      ],
      "metadata": {
        "id": "wi0BCcL1_hUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ChartParser\n",
        "\n",
        "parser = ChartParser(grammar)\n",
        "sent = ['a', 'cat', 'chased', 'a', 'dog']\n",
        "for tree in parser.parse(sent):\n",
        "    print(tree)"
      ],
      "metadata": {
        "id": "CLlocZf0LmtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not very easy to interpret, let's add a graphical parse tree:"
      ],
      "metadata": {
        "id": "K-snwT1RDqs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "    tree.pretty_print(unicodelines=True, nodedist=4)\n"
      ],
      "metadata": {
        "id": "kpMmqyljD54x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's better. Let's try another one:"
      ],
      "metadata": {
        "id": "X1_1pqYhEmkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['the', 'cat', 'sat', 'on', 'the', 'dog']\n",
        "parser = ChartParser(grammar)\n",
        "parser.parse(sent)\n",
        "for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "    tree.pretty_print(unicodelines=True, nodedist=4)"
      ],
      "metadata": {
        "id": "GYD14oxwFCWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oops that didn't work. NLTK is not very informative here about what's gone wrong, but the fact that there is no output means that there was no parse found. We can easily see that all the lexical items (words) in *the cat sat on the dog* are present in the grammar, so the issue must be with the other production rules.\n",
        "\n",
        "Your task now is to add rules to the grammar from above so that it can parse *the cat sat on the dog*. (You'll know the grammar can parse it when you can see the parse tree).\n",
        "\n",
        "We've copied the grammar and parsing code below for convenience:"
      ],
      "metadata": {
        "id": "4stV-MugFq7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EDIT THE GRAMMAR BELOW\n",
        "# Original grammar\n",
        "# grammar = CFG.fromstring(\"\"\"\n",
        "#     S -> NP VP\n",
        "#     PP -> P NP\n",
        "#     NP -> Det N | NP PP\n",
        "#     VP -> V NP | VP PP\n",
        "#     Det -> 'a' | 'the'\n",
        "#     N -> 'dog' | 'cat'\n",
        "#     V -> 'chased' | 'sat'\n",
        "#     P -> 'on' | 'in'\n",
        "# \"\"\")\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    PP -> P NP\n",
        "    NP -> Det N | NP PP\n",
        "    VP -> V NP | VP PP | V\n",
        "    Det -> 'a' | 'the'\n",
        "    N -> 'dog' | 'cat'\n",
        "    V -> 'chased' | 'sat'\n",
        "    P -> 'on' | 'in'\n",
        "\"\"\")\n",
        "\n",
        "sent = ['the', 'cat', 'sat', 'on', 'the', 'dog']\n",
        "parser = ChartParser(grammar)\n",
        "parser.parse(sent)\n",
        "for tree in parser.parse(sent):\n",
        "    print(tree)\n",
        "    tree.pretty_print(unicodelines=True, nodedist=4)"
      ],
      "metadata": {
        "id": "OjX6xqG5L720"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**: Extend the grammar further to allow you to parse some of the example sentences from this week's lecture:\n",
        "\n",
        "    Anne brought a chair.\n",
        "    They love classes.\n",
        "    John saw the man with a telescope.\n",
        "    Mary and John like to eat apples in their garden at night.\n",
        "\n",
        "We would recommend that you do this one sentence at a time, starting with the first one (remember to uncomment the appropriate line in the code).\n",
        "\n",
        "To get you started, we have again copied the grammar and parsing code for you below. Note that we are now using part of speech tags from the Brown Corpus to enable finer-grained control over possible sentences (except that we're keeping the Det tag): https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used\n",
        "\n",
        "Use the Brown Corpus page to identify appropriate part-of-speech tags (pre-terminals) to use. Consider using NNS=singular noun, NNP=proper nount, PRPS=plural personal pronoun, VBD=past tense verb, CC=coordinating conjunction, etc.\n",
        "\n",
        "Make sure the parser gives you both parses from the Week 2 lecture for sentence 3.\n",
        "\n",
        "If you get stuck on the last sentence, enter the sentence here: https://corenlp.run/ (select just 'constituency parse' in the Annotations box). Then consult the resulting parse tree produced by the parser there for inspiration."
      ],
      "metadata": {
        "id": "pjn6q0rpL3PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 -- ADD YOUR OWN CODE BELOW (FOR INSTRUCTIONS SEE TEXT BOX DIRECTLY ABOVE):\n",
        "# Original grammar\n",
        "# grammar = CFG.fromstring(\"\"\"\n",
        "#     S -> NP VP\n",
        "#     PP -> P NP\n",
        "#     NP -> Det N | NP PP\n",
        "#     VP -> V NP | VP PP | V\n",
        "#     Det -> 'a' | 'the'\n",
        "#     N -> 'dog' | 'cat'\n",
        "#     V -> 'chased' | 'sat'\n",
        "#     P -> 'on' | 'in'\n",
        "# \"\"\")\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP | PRP VP\n",
        "    PP -> IN NP | IN NN | IN VP\n",
        "    NP -> Det NN | NP PP | NNP | NNS\n",
        "    VP -> VBD NP | VP PP | VBD | VBP | VBP NP | VB NP\n",
        "    Det -> 'a' | 'the' | 'their'\n",
        "    NN -> 'dog' | 'cat' | 'chair' | 'man' | 'telescope' | 'night' | 'garden'\n",
        "    NNS -> 'classes' | 'apples'\n",
        "    NNP -> 'Anne' | 'John' | 'Mary'\n",
        "    VBD -> 'chased' | 'sat' | 'brought' | 'saw'\n",
        "    VBP -> 'love' | 'like' | 'eat' | 'loves' | 'likes' | 'eats'\n",
        "    VB -> 'love' | 'like' | 'eat'\n",
        "    IN -> 'on' | 'in' | 'with' | 'to' | 'at'\n",
        "    PRP -> 'they'\n",
        "    CC -> 'and' | 'or' | 'but'\n",
        "\"\"\")\n",
        "\n",
        "# grammar = CFG.fromstring(\"\"\"\n",
        "#     S -> NP VP | PronSubj VP\n",
        "#     PP -> IN NP | IN VP | IN N\n",
        "#     NP -> Det N | NP PP | Npl | Npr | NP Conj NP\n",
        "#     VP -> V NP | VP PP | V\n",
        "#     Det -> 'a' | 'the' | 'their'\n",
        "#     N -> 'dog' | 'cat' | 'chair' | 'man' | 'telescope' | 'garden' | 'night'\n",
        "#     Npl -> 'cats' | 'classes' | 'apples'\n",
        "#     Npr -> 'Anne' | 'John' | 'Mary'\n",
        "#     V -> 'chased' | 'sat' | 'brought' | 'saw' | 'love' | 'like' | 'eat'\n",
        "#     IN -> 'on' | 'in' | 'with' | 'at' | 'to'\n",
        "#     PronSubj -> 'they'\n",
        "#     Conj -> 'and' | 'or' | 'but'\n",
        "# \"\"\")\n",
        "\n",
        "parser = ChartParser(grammar)\n",
        "\n",
        "sent_1 = ['Anne', 'brought', 'a', 'chair']\n",
        "sent_2 = ['they', 'love', 'classes']\n",
        "sent_3 = ['John', 'saw', 'the', 'man', 'with', 'a', 'telescope']\n",
        "sent_4 = ['they', 'like', 'to', 'eat', 'apples', 'in', 'their', 'garden', 'at', 'night']\n",
        "# sent_5 = ['Mary', 'and', 'John', 'like', 'to', 'eat', 'apples', 'in', 'their', 'garden', 'at', 'night']\n",
        "\n",
        "sentence_to_parse=sent_4\n",
        "\n",
        "for tree in parser.parse(sentence_to_parse):\n",
        "    print(tree)\n",
        "    tree.pretty_print(unicodelines=True, nodedist=4)"
      ],
      "metadata": {
        "id": "pXvLz8AYGCvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow that's a lot of parses for sentence 4 - are they all correct? How do they differ? Can you pinpoint parse errors?"
      ],
      "metadata": {
        "id": "CG2FCuGnfQId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating sentences with a CFG\n",
        "\n",
        "CFGs like the ones we've been working with are reversible, meaning they can be used to generate sentences as well as parse them.\n",
        "\n",
        "Let's try generating the first 10 sentences with the following grammar adapted from the second one above.\n",
        "\n",
        "First we importe the generate module, then we use the generate function to generate n=20 sentences using generation trees of depth up to 5. For more info see https://www.nltk.org/api/nltk.parse.generate.html"
      ],
      "metadata": {
        "id": "-u5SUM0sEa-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.parse.generate import generate\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    PP -> IN NP\n",
        "    NP -> DetDef NNS | Det NN | NP PP | NNS\n",
        "    VP -> VBZ NP | VBD NP | VP PP\n",
        "    Det -> DetDef | DetIndef\n",
        "    DetIndef -> 'a'\n",
        "    DetDef -> 'the'\n",
        "    NN -> 'dog' | 'cat'\n",
        "    NNS -> 'dogs' | 'cats'\n",
        "    VBZ -> 'chases' | 'sits'\n",
        "    VBD -> 'chased' | 'sat'\n",
        "    IN -> 'on' | 'in'\n",
        "\"\"\")\n",
        "\n",
        "num_sents_to_generate = 200\n",
        "\n",
        "for n, sent in enumerate(generate(grammar, depth=5, n=num_sents_to_generate), 1):\n",
        "    print(\"%3d. %s\" % (n, \" \".join(sent)))"
      ],
      "metadata": {
        "id": "rZC3c_R5Hb7c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's a whole lot of ungrammatical sentences! Your next task is to fix the most egregious grammatical errors. We've again copied the code below for convenience.\n",
        "\n",
        "**Task 2**: Edit the grammar below to get number agreement right, i.e. so that (a) plural nouns are only generated with plural verbs; and (b) the determiner 'a' is not generated with plural nouns."
      ],
      "metadata": {
        "id": "0NCPpSFRc1E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2 -- ADD YOUR OWN CODE BELOW:\n",
        "# grammar = CFG.fromstring(\"\"\"\n",
        "#     S -> NP VP\n",
        "#     PP -> IN NP\n",
        "#     NP -> DetDef NNS | Det NN | NP PP | NNS\n",
        "#     VP -> VBZ NP | VBD NP | VP PP\n",
        "#     Det -> DetDef | DetIndef\n",
        "#     DetIndef -> 'a'\n",
        "#     DetDef -> 'the'\n",
        "#     NN -> 'dog' | 'cat'\n",
        "#     NNS -> 'dogs' | 'cats'\n",
        "#     VBZ -> 'chases' | 'sits'\n",
        "#     VBD -> 'chased' | 'sat'\n",
        "#     IN -> 'on' | 'in'\n",
        "# \"\"\")\n",
        "\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    PP -> IN NP\n",
        "    NP -> Det NN | NP PP\n",
        "    NPS -> DetDef NNS | NP PP | NNS\n",
        "    VP -> VBZ NP | VBD NP | VP PP\n",
        "    Det -> DetDef | DetIndef\n",
        "    DetIndef -> 'a'\n",
        "    DetDef -> 'the'\n",
        "    NN -> 'dog' | 'cat'\n",
        "    NNS -> 'dogs' | 'cats'\n",
        "    VBZ -> 'chases' | 'sits'\n",
        "    VBD -> 'chased' | 'sat'\n",
        "    IN -> 'on' | 'in'\n",
        "\"\"\")\n",
        "\n",
        "num_sents_to_generate = 20\n",
        "\n",
        "for n, sent in enumerate(generate(grammar, depth=5, n=num_sents_to_generate), 1):\n",
        "    print(\"%3d. %s\" % (n, \" \".join(sent)))"
      ],
      "metadata": {
        "id": "mk9WZ-okdIMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Submitting your work for Week 3\n",
        "\n",
        "Once you have completed the work for Task 1 and Task 2, please copy the whole notebook to the folder that you have shared with the module team.\n",
        "\n",
        "We will make a sample solution available in Week 4."
      ],
      "metadata": {
        "id": "Y7X6r5NpVX-h"
      }
    }
  ]
}